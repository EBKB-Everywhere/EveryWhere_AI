# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„¤ì¹˜ ëª…ë ¹ì–´: pip install -r requirements.txt
# ë˜ëŠ”: pip install fastapi uvicorn pymysql google-generativeai pydantic
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


import sys

REQUIRED_PACKAGES = {
    'fastapi': 'fastapi',
    'uvicorn': 'uvicorn',
    'pymysql': 'pymysql',
    'google.genai': 'google-generativeai',
    'pydantic': 'pydantic'
}


missing_packages = []

for module_name, package_name in REQUIRED_PACKAGES.items():
    try:
        __import__(module_name)
    except ImportError:
        missing_packages.append(package_name)

if missing_packages:
    print("âŒ ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
    for pkg in missing_packages:
        print(f"   - {pkg}")
    print("\nğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print(f"   pip install {' '.join(missing_packages)}")
    sys.exit(1)


import json
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from reco import recommend_rooms  #  ì¶”ì²œ ëª¨ë¸ í•¨ìˆ˜
import pymysql
from contextlib import contextmanager

from google import genai
from google.genai import types

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„¤ì • 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MY_GEMINI_API_KEY = "AIzaSyDGuN4D3ZDvFWxii5D0U_-pn420C_EAx-k"  # Gemini API í‚¤ ì„¤ì • í•„ìš”

# DB ì„¤ì •
DB_CONFIG = {
    "host": "localhost",
    "port": 3306,
    "user": "your_user",
    "password": "your_password",
    "database": "your_database",
    "charset": "utf8mb4"
}

app = FastAPI(title="AI Space Recommendation API")
client = genai.Client(api_key=MY_GEMINI_API_KEY)

# ëª¨ë¸ ë¡œë“œ
model = joblib.load("crowd_classifier.pkl")

top_features = [
    'mfcc_9_mean', 'mfcc_7_mean', 'zcr', 'band0_300',
    'numberOfHuman', 'speech_noise_ratio', 'mfcc_3_mean',
    'mfcc_14_mean', 'mfcc_8_mean', 'centroid', 'bleNum'
]

# ì‚¬ëŒ ìˆ˜ ê°ì§€ í•¨ìˆ˜
def count_people(image_path):
    # YOLOv8 ëª¨ë¸ ë¡œë“œ
    model = YOLO("yolov8n.pt")
    img = cv2.imread(image_path)

    if img is None:
        print(f"[WARNING] Cannot read: {image_path}")
        return 0

    results = model(img, verbose=False)
    boxes = results[0].boxes
    
    person_count = 0

    for box in boxes:
        cls = int(box.cls)
        if cls == 0:  # YOLOì˜ person í´ë˜ìŠ¤ ID = 0
            person_count += 1

    return person_count

# -----------------------------
# 1. ë°´ë“œ ì—ë„ˆì§€ ê³„ì‚°ìš© ë³´ì¡° í•¨ìˆ˜
# -----------------------------
def band_energy(signal, sr, low, high):
    fft = np.abs(np.fft.rfft(signal))
    freqs = np.fft.rfftfreq(len(signal), d=1.0/sr)
    idx = np.where((freqs >= low) & (freqs <= high))[0]
    return fft[idx].mean() if len(idx) > 0 else 0


# -----------------------------
# 2. SPL ê³„ì‚°
# -----------------------------
def calc_spl(signal):
    rms = np.sqrt(np.mean(signal ** 2))
    return 20 * np.log10(rms + 1e-7)


# -----------------------------
# 3. MFCC + ì¡ìŒ ë³´ì •
# -----------------------------
def extract_mfcc(signal, sr, n_mfcc=20):
    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)
    return mfcc.mean(axis=1), mfcc.var(axis=1)


# -----------------------------
# 4. ì „ì²´ ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ
# -----------------------------
def extract_audio_features(path=r"C:\realthon_t6\vid1.wav", n_mfcc=20):
    signal, sr = librosa.load(path, sr=None)

    # 1) SPL
    spl = calc_spl(signal)

    # 2) MFCC mean + var
    mfcc_mean, mfcc_var = extract_mfcc(signal, sr, n_mfcc=n_mfcc)

    # 3) ZCR
    zcr = librosa.feature.zero_crossing_rate(y=signal).mean()

    # 4) Centroid
    centroid = librosa.feature.spectral_centroid(y=signal, sr=sr).mean()

    # 5) Band energies
    band0_300 = band_energy(signal, sr, 0, 300)
    band300_3000 = band_energy(signal, sr, 300, 3000)
    band3000_8000 = band_energy(signal, sr, 3000, 8000)

    band_ratio_speech = band300_3000 / (band0_300 + 1e-7)

    # ëª¨ë“  feature í‰íƒ„í™”í•´ì„œ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ í•©ì¹¨
    features = {
        "spl": spl,
        "zcr": zcr,
        "centroid": centroid,
        "band0_300": band0_300,
        "band300_3000": band300_3000,
        "band3000_8000": band3000_8000,
        "speech_noise_ratio": band_ratio_speech,
    }

    # MFCC ì¶”ê°€
    for i, v in enumerate(mfcc_mean):
        features[f"mfcc_{i}_mean"] = v
    for i, v in enumerate(mfcc_var):
        features[f"mfcc_{i}_var"] = v

    return features 

def build_features(img_path, ble_raw, audio_path):
    img_count = count_people(img_path)
    ble_feats = ble_raw
    audio_feats = extract_audio_features(audio_path)

    row = {
        "numberOfHuman": img_count,
        "bleNum": ble_feats,
        **audio_feats
    }
    return row 

def predict_crowd(ID, img_path, ble_raw, audio_path):
    """
    feature_dict ì˜ˆì‹œ:
    {
       "mfcc_9_mean": -132.1,
       "mfcc_7_mean": 22.3,
       "zcr": 0.01,
       "band0_300": 47.1,
       "numberOfHuman": 14,
       "speech_noise_ratio": 0.22,
       "mfcc_3_mean": 30.4,
       "mfcc_14_mean": 4.12,
       "mfcc_8_mean": -2.11,
       "centroid": 1750.2,
       "bleNum": 83
    }
    """
    feature_dict = build_features(img_path, ble_raw, audio_path)
    row = {f: feature_dict[f] for f in top_features}

    df = pd.DataFrame([row])
    pred = model.predict(df)[0]            # class 0/1/2
    prob = model.predict_proba(df)[0]      # softmax í™•ë¥ 

    if pred == 0:
        result = round(6+random.uniform(-6, 6))
    elif pred == 1:
        result = round(19+random.uniform(-7, 7))
    else:
        result = round(32+random.uniform(-6, 6))
        
    return ID, result
    
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pydantic ëª¨ë¸ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2-1. AIëª¨ë¸1 í˜¸ì¶œ API Request (BE -> AI)
class AiPredictCountRequest(BaseModel):
    spaceId: int
    imagePath: str
    bluetooth: int
    audioFile: Optional[Any]

# 2-1. AIëª¨ë¸1 í˜¸ì¶œ API Response (AI -> BE)
class AiPredictCountResponse(BaseModel):
    spaceId: int
    predictCount: int

class NLPRequest(BaseModel):
    userText: str = Field(..., description="ì‚¬ìš©ìì˜ ìì—°ì–´ ì…ë ¥")
    topN: int = Field(default=3, description="ì¶”ì²œí•  ê³µê°„ ê°œìˆ˜")

class NLPCandidateRoom(BaseModel):
    spaceId: int
    spaceName: str
    purposeScore: float

class NLPResponse(BaseModel):
    candidateRooms: List[NLPCandidateRoom]
    placeFlag: int
    placeLat: float
    placeLng: float

class RecommendRequest(BaseModel):
    # reco.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” candidate_rooms ê·¸ëŒ€ë¡œ ë§ì¶¤
    candidateRooms: List[Dict[str, Any]]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DB ì—°ê²° ê´€ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@contextmanager
def get_db_connection():
    """DB ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        yield conn
    except Exception as e:
        if conn:
            conn.rollback()
        raise e
    finally:
        if conn:
            conn.close()

def fetch_all_spaces() -> List[Dict[str, Any]]:
    """DBì—ì„œ ëª¨ë“  ê³µê°„ ì •ë³´ ì¡°íšŒ"""
    with get_db_connection() as conn:
        with conn.cursor(pymysql.cursors.DictCursor) as cursor:
            query = """
                SELECT 
                    space_id,
                    space_name,
                    space_lat,
                    space_lon,
                    space_floor,
                    space_capacity,
                    quite_score,
                    talk_score,
                    study_score,
                    rest_score
                FROM Space
            """
            cursor.execute(query)
            return cursor.fetchall()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Gemini NLP ëª¨ë¸ (ëª¨ë¸ 1)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GEMINI_SCHEMA: Dict[str, Any] = {
    "type": "OBJECT",
    "properties": {
        "topSpaces": {
            "type": "ARRAY",
            "items": {
                "type": "OBJECT",
                "properties": {
                    "spaceId": {"type": "INTEGER"},
                    "purposeScore": {"type": "NUMBER"},
                },
                "required": ["spaceId", "purposeScore"],
            },
        },
        "placeFlag": {
            "type": "INTEGER",
            "description": "ì‹¤ì œ ì¥ì†Œ ì–¸ê¸‰ ì—¬ë¶€ (1/0)",
        },
        "placeName": {
            "type": "STRING",
            "description": "ì‚¬ìš©ìê°€ ë§í•œ ì‹¤ì œ ì¥ì†Œëª… (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
        },
    },
    "required": ["topSpaces", "placeFlag", "placeName"],
}

def _call_gemini(
    user_text: str,
    spaces: List[Dict[str, Any]],
    top_n: int,
) -> Dict[str, Any]:
    """Gemini API í˜¸ì¶œ"""
    spaces_for_llm = [
        {
            "spaceId": s["space_id"],
            "vector": [
                s["quite_score"],
                s["talk_score"],
                s["study_score"],
                s["rest_score"],
            ],
        }
        for s in spaces
    ]
    spaces_json = json.dumps(spaces_for_llm, ensure_ascii=False)

    prompt = f"""
ë„ˆëŠ” ìº í¼ìŠ¤ ê³µê°„ ì¶”ì²œ ëª¨ë¸ì´ë‹¤.

- spaces: ê° ê³µê°„ì€ spaceIdì™€ vectorë¥¼ ê°€ì§„ë‹¤.
  vectorëŠ” ["ì¡°ìš©í•œ", "ëŒ€í™”í•˜ëŠ”", "ê³µë¶€í•˜ëŠ”", "íœ´ì‹í•˜ëŠ”"] ìˆœì„œì˜ ì ìˆ˜ì´ë‹¤.
- user_text: í•œêµ­ì–´ ë¬¸ì¥.

1. user_textë¥¼ ë¶„ì„í•´ì„œ ìœ„ 4ì°¨ì›ì— ëŒ€í•œ intent_vectorë¥¼ ë§ˆìŒì†ìœ¼ë¡œ ë§Œë“ ë‹¤.
2. ê° ê³µê°„ì˜ vectorì™€ intent_vector ì‚¬ì´ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ì„œ purposeScoreë¡œ ì‚¬ìš©í•œë‹¤.
   cos_sim(a, b) = (Î£ a_i * b_i) / (sqrt(Î£ a_i^2) * sqrt(Î£ b_i^2))
3. purposeScoreë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìƒìœ„ {top_n}ê°œ ê³µê°„ë§Œ
   topSpaces ë°°ì—´ì— ë„£ëŠ”ë‹¤.
   ê° í•­ëª©ì€ {{ "spaceId", "purposeScore" }} ë§Œ í¬í•¨í•´ì•¼ í•œë‹¤.
4. user_text ì•ˆì— ì‹¤ì œ ì¥ì†Œëª…ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ ë³´ê³ ,
   - ì–¸ê¸‰ë˜ë©´ placeFlag = 1, placeName ì— ëŒ€í‘œ ì¥ì†Œëª…ì„ ë¬¸ìì—´ë¡œ ë„£ëŠ”ë‹¤.
   - ì•„ë‹ˆë©´ placeFlag = 0, placeName = "".

! ìœ„ë„/ê²½ë„(lat/lng)ëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆë¼.
! ì¶œë ¥ì€ ë‚´ê°€ ì œê³µí•œ GEMINI_SCHEMAì— ì •í™•íˆ ë§ëŠ” ìˆœìˆ˜ JSONë§Œ í¬í•¨í•œë‹¤.
   ìì—°ì–´ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.

spaces(JSON):
{spaces_json}

user_text:
\"\"\"{user_text}\"\"\"
"""

    resp = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=GEMINI_SCHEMA,
        ),
    )
    return json.loads(resp.text)

def _find_space_by_partial_name(
    spaces: List[Dict[str, Any]],
    place_name: str,
) -> Optional[Dict[str, Any]]:
    """ë¶€ë¶„ ë¬¸ìì—´ë¡œ ê³µê°„ ê²€ìƒ‰"""
    norm_place = place_name.strip().lower()
    if not norm_place:
        return None

    for s in spaces:
        norm_space = str(s["space_name"]).strip().lower()
        if not norm_space:
            continue

        if norm_place in norm_space or norm_space in norm_place:
            return s

    return None

def run_nlp_model(
    user_text: str,
    spaces: List[Dict[str, Any]],
    top_n: int = 3,
) -> Dict[str, Any]:
    """NLP ëª¨ë¸ ì‹¤í–‰ (ëª©ì  ì ìˆ˜ ê³„ì‚°)"""
    gemini_res = _call_gemini(user_text, spaces, top_n)
    by_id = {s["space_id"]: s for s in spaces}

    candidate_rooms: List[Dict[str, Any]] = []
    for item in gemini_res["topSpaces"]:
        sid = item["spaceId"]
        score = item["purposeScore"]
        base = by_id.get(sid)
        if not base:
            continue

        candidate_rooms.append(
            {
                "spaceId": sid,
                "spaceName": base["space_name"],
                "purposeScore": score,
            }
        )

    place_flag = gemini_res["placeFlag"]
    place_name = gemini_res.get("placeName", "") or ""

    place_lat, place_lng = 0.0, 0.0
    if place_flag == 1 and place_name:
        space_row = _find_space_by_partial_name(spaces, place_name)
        if space_row is not None:
            place_lat = float(space_row.get("space_lat", 0.0))
            place_lng = float(space_row.get("space_lon", 0.0))

    return {
        "candidateRooms": candidate_rooms,
        "placeFlag": place_flag,
        "placeLat": place_lat,
        "placeLng": place_lng,
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ì—”ë“œí¬ì¸íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2-1. AIëª¨ë¸1 í˜¸ì¶œ API (ì¸ì›ìˆ˜ ê³„ì‚°)
@app.post("/ai/predict/count", response_model=AiPredictCountResponse)
async def predict_count_endpoint(request: AiPredictCountRequest):
    """
    AI ëª¨ë¸ 1 (í˜¼ì¡ë„ ì¸ì›ìˆ˜ ê³„ì‚°)
    """

    ID, result = predict_crowd(request.spaceId, request.imagePath, request.bluetooth, request.audioFile)
    # **AI ë¡œì§ ë”ë¯¸:** ìš”ì²­ëœ spaceIdë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ì˜ì˜ ì¸ì›ìˆ˜ ë°˜í™˜
    dummy_count = 10 + math.ceil(math.sin(request.spaceId * 10) * 5)

    return AiPredictCountResponse(
        spaceId=request.spaceId,
        predictCount=int(result)
    )


@app.post("/api/internal/ai/nlp", response_model=NLPResponse)
async def nlp_endpoint(request: NLPRequest):
    """
    NLP ëª¨ë¸ API
    ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ëª©ì  ì ìˆ˜(purposeScore) ê³„ì‚° ë° ì¥ì†Œ ì •ë³´ ë°˜í™˜
    
    Returns:
    {
      "candidateRooms": [
        { "spaceId": 201, "spaceName": "ì¤‘ì•™ë„ì„œê´€", "purposeScore": 0.9 },
        { "spaceId": 305, "spaceName": "ì¹´í˜", "purposeScore": 0.7 }
      ],
      "placeFlag": 1,
      "placeLat": 37.55,
      "placeLng": 126.94
    }
    """
    if not MY_GEMINI_API_KEY:
        raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        # DBì—ì„œ ëª¨ë“  ê³µê°„ ì •ë³´ ì¡°íšŒ
        spaces = fetch_all_spaces()
        
        if not spaces:
            raise HTTPException(status_code=404, detail="ê³µê°„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # NLP ëª¨ë¸ ì‹¤í–‰
        result = run_nlp_model(request.userText, spaces, request.topN)
        
        return NLPResponse(**result)
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"NLP ëª¨ë¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
@app.post("/api/internal/ai/recommend")
async def recommend_endpoint(request: RecommendRequest):
    """
    ì¶”ì²œ ëª¨ë¸ 2 API

    Body ì˜ˆì‹œ:
    {
      "candidateRooms": [
        {
          "spaceId": 201,
          "spaceName": "ì¤‘ì•™ë„ì„œê´€",
          "purposeScore": 0.9,
          "distanceFeature": 0.88,
          "predictCount": 18,
          "capacity": 40
        },
        ...
      ]
    }

    -> reco.recommend_rooms() í˜¸ì¶œí•´ì„œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
    """
    try:
        result = recommend_rooms(request.candidateRooms)
        return {"results": result}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ëª¨ë¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "service": "AI Space Recommendation API"}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
